{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cc2ce40c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from sklearn.metrics import ndcg_score\n",
    "import joblib\n",
    "from catboost import CatBoostRanker, Pool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d3e3cf05",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR = Path(\"range_features\")\n",
    "MODEL_DIR = Path(\"models\")\n",
    "MODEL_DIR.mkdir(exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5d9fd030",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_group_sizes(df):\n",
    "    return df.groupby([\"visitorid\", \"anchor_session_id\"]).size().tolist()\n",
    "\n",
    "\n",
    "def split_train_valid(df, valid_frac=0.2):\n",
    "    split_point = df[\"anchor_ts\"].quantile(1.0 - valid_frac)\n",
    "    return df[df[\"anchor_ts\"] < split_point].copy(), df[\n",
    "        df[\"anchor_ts\"] >= split_point\n",
    "    ].copy()\n",
    "\n",
    "\n",
    "def eval_ndcg_per_group(df, preds, ks=(5, 10, 20)):\n",
    "    metrics = {}\n",
    "    sizes = build_group_sizes(df)\n",
    "    labels = df[\"gain\"].values\n",
    "    start = 0\n",
    "    for k in ks:\n",
    "        vals = []\n",
    "        start = 0\n",
    "        for sz in sizes:\n",
    "            if sz < 2:\n",
    "                start += sz\n",
    "                continue\n",
    "            y = labels[start : start + sz]\n",
    "            p = preds[start : start + sz]\n",
    "            vals.append(ndcg_score([y], [p], k=k))\n",
    "            start += sz\n",
    "        metrics[f\"ndcg_{k}\"] = float(np.mean(vals)) if vals else np.nan\n",
    "    return metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0ea4aca6",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_valid = pd.read_parquet(DATA_DIR / \"train_X.parquet\")\n",
    "test = pd.read_parquet(DATA_DIR / \"test_X.parquet\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7935abef",
   "metadata": {},
   "source": [
    "train_valid слишком здоровенный получился не могу обучить на всем датасете"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0abcc8ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "pos = train_valid[train_valid[\"gain\"] > 0]\n",
    "neg = train_valid[train_valid[\"gain\"] == 0].sample(\n",
    "    n=len(pos) * 8, random_state=42\n",
    ")  # ratio 1:x\n",
    "train_valid = pd.concat([pos, neg])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ad6efc7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "BASE_FEATURES = [\n",
    "    \"als_score\",\n",
    "    \"sim_max\",\n",
    "    \"item_pop_w\",\n",
    "    \"sess_n_events\",\n",
    "    \"sess_n_items\",\n",
    "    \"sess_duration\",\n",
    "    \"sess_cnt_view\",\n",
    "    \"sess_cnt_addtocart\",\n",
    "    \"sess_cnt_transaction\",\n",
    "    \"available\",\n",
    "    \"categoryid\",\n",
    "    \"root_category\",\n",
    "    \"level_0\",\n",
    "    \"level_1\",\n",
    "    \"level_2\",\n",
    "    \"level_3\",\n",
    "    \"level_4\",\n",
    "    \"level_5\",\n",
    "    \"value_count\",\n",
    "    \"value_mean\",\n",
    "    \"value_std\",\n",
    "    \"value_min\",\n",
    "    \"value_max\",\n",
    "]\n",
    "DROP = [\"visitorid\", \"anchor_session_id\", \"itemid\", \"anchor_ts\", \"gain\", \"timestamp\"]\n",
    "\n",
    "features = [c for c in BASE_FEATURES if c in train_valid.columns]\n",
    "\n",
    "\n",
    "cat_features = [\n",
    "    c\n",
    "    for c in [\n",
    "        \"available\",\n",
    "        \"categoryid\",\n",
    "        \"root_category\",\n",
    "        \"level_0\",\n",
    "        \"level_1\",\n",
    "        \"level_2\",\n",
    "        \"level_3\",\n",
    "        \"level_4\",\n",
    "        \"level_5\",\n",
    "    ]\n",
    "    if c in features\n",
    "]\n",
    "num_features = [c for c in features if c not in cat_features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2230f8b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_categorical_to_str(df: pd.DataFrame, cat_features: list) -> pd.DataFrame:\n",
    "    df_copy = df.copy()\n",
    "\n",
    "    for feature in cat_features:\n",
    "        if feature in df_copy.columns:\n",
    "            df_copy[feature] = df_copy[feature].astype(str)\n",
    "\n",
    "    return df_copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "27f09a67",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_valid = convert_categorical_to_str(train_valid, cat_features)\n",
    "test = convert_categorical_to_str(test, cat_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c2a75618",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_part, valid_part = split_train_valid(train_valid)\n",
    "\n",
    "del train_valid\n",
    "\n",
    "\n",
    "# Создаем group_id колонки\n",
    "train_part[\"group_id\"] = (\n",
    "    train_part[\"visitorid\"].astype(str)\n",
    "    + \"_\"\n",
    "    + train_part[\"anchor_session_id\"].astype(str)\n",
    ")\n",
    "valid_part[\"group_id\"] = (\n",
    "    valid_part[\"visitorid\"].astype(str)\n",
    "    + \"_\"\n",
    "    + valid_part[\"anchor_session_id\"].astype(str)\n",
    ")\n",
    "\n",
    "# Сортируем по group_id\n",
    "train_part = train_part.sort_values(\"group_id\").reset_index(drop=True)\n",
    "valid_part = valid_part.sort_values(\"group_id\").reset_index(drop=True)\n",
    "\n",
    "# Теперь создаем Pool\n",
    "train_pool = Pool(\n",
    "    train_part[features],\n",
    "    label=train_part[\"gain\"],\n",
    "    group_id=train_part[\"group_id\"],\n",
    "    cat_features=cat_features,\n",
    ")\n",
    "\n",
    "valid_pool = Pool(\n",
    "    valid_part[features],\n",
    "    label=valid_part[\"gain\"],\n",
    "    group_id=valid_part[\"group_id\"],\n",
    "    cat_features=cat_features,\n",
    ")\n",
    "\n",
    "# модель CatBoostRanker\n",
    "model = CatBoostRanker(\n",
    "    iterations=1500,\n",
    "    learning_rate=0.05,\n",
    "    depth=8,\n",
    "    l2_leaf_reg=3.0,\n",
    "    loss_function=\"YetiRank\",\n",
    "    eval_metric=\"NDCG:top=10\",\n",
    "    random_seed=42,\n",
    "    od_type=\"Iter\",\n",
    "    od_wait=50,\n",
    "    use_best_model=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e88590d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Groupwise loss function. OneHotMaxSize set to 10\n",
      "0:\ttest: 0.8049447\tbest: 0.8049447 (0)\ttotal: 1.36s\tremaining: 33m 58s\n",
      "100:\ttest: 0.9055616\tbest: 0.9055616 (100)\ttotal: 1m 49s\tremaining: 25m 16s\n",
      "200:\ttest: 0.9128306\tbest: 0.9128306 (200)\ttotal: 3m 39s\tremaining: 23m 40s\n",
      "300:\ttest: 0.9164355\tbest: 0.9164633 (298)\ttotal: 5m 29s\tremaining: 21m 53s\n",
      "400:\ttest: 0.9179489\tbest: 0.9179588 (399)\ttotal: 7m 20s\tremaining: 20m 7s\n",
      "500:\ttest: 0.9190752\tbest: 0.9191437 (493)\ttotal: 9m 11s\tremaining: 18m 19s\n",
      "600:\ttest: 0.9195284\tbest: 0.9195559 (588)\ttotal: 11m\tremaining: 16m 28s\n",
      "700:\ttest: 0.9203721\tbest: 0.9203721 (700)\ttotal: 12m 50s\tremaining: 14m 38s\n",
      "800:\ttest: 0.9205645\tbest: 0.9205645 (800)\ttotal: 14m 36s\tremaining: 12m 44s\n",
      "900:\ttest: 0.9209521\tbest: 0.9209591 (899)\ttotal: 16m 21s\tremaining: 10m 52s\n",
      "1000:\ttest: 0.9213550\tbest: 0.9213950 (999)\ttotal: 18m 8s\tremaining: 9m 2s\n",
      "1100:\ttest: 0.9216654\tbest: 0.9216672 (1092)\ttotal: 19m 55s\tremaining: 7m 13s\n",
      "1200:\ttest: 0.9220625\tbest: 0.9220671 (1197)\ttotal: 21m 40s\tremaining: 5m 23s\n",
      "1300:\ttest: 0.9222227\tbest: 0.9222417 (1296)\ttotal: 23m 26s\tremaining: 3m 35s\n",
      "Stopped by overfitting detector  (50 iterations wait)\n",
      "\n",
      "bestTest = 0.9222416639\n",
      "bestIteration = 1296\n",
      "\n",
      "Shrink model to first 1297 iterations.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<catboost.core.CatBoostRanker at 0x7bf5e03140d0>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# обучение\n",
    "model.fit(train_pool, eval_set=valid_pool, verbose=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "caea72cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valid metrics: {'ndcg_5': 0.7545993596910043, 'ndcg_10': 0.7682340738536737, 'ndcg_20': 0.7719175556646417}\n"
     ]
    }
   ],
   "source": [
    "# валидация\n",
    "pv = model.predict(valid_pool)\n",
    "\n",
    "\n",
    "valid_metrics = eval_ndcg_per_group(valid_part, pv)\n",
    "\n",
    "print(\"Valid metrics:\", valid_metrics)\n",
    "\n",
    "test[\"group_id\"] = (\n",
    "    test[\"visitorid\"].astype(str) + \"_\" + test[\"anchor_session_id\"].astype(str)\n",
    ")\n",
    "\n",
    "test = test.sort_values(\"group_id\").reset_index(drop=True)\n",
    "\n",
    "# тест\n",
    "test_pool = Pool(\n",
    "    test[features],\n",
    "    label=test[\"gain\"],\n",
    "    group_id=test[\"group_id\"],\n",
    "    cat_features=cat_features,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d0dcaffa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test metrics: {'ndcg_5': 0.6588970793415756, 'ndcg_10': 0.6633743605540435, 'ndcg_20': 0.6664979058737888}\n"
     ]
    }
   ],
   "source": [
    "pt = model.predict(test_pool)\n",
    "\n",
    "test_metrics = eval_ndcg_per_group(test, pt)\n",
    "print(\"Test metrics:\", test_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d9107886",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['models/cat_features_8.pkl']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# сохраняем модель\n",
    "model.save_model(str(MODEL_DIR / \"catboost_ranker_8.cbm\"))\n",
    "joblib.dump(cat_features, MODEL_DIR / \"cat_features_8.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a6d40e63",
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlflow\n",
    "\n",
    "from utils_mlflow import setup_mlflow_client, setup_env\n",
    "\n",
    "setup_env()\n",
    "\n",
    "client = setup_mlflow_client()\n",
    "\n",
    "EXPERIMENT_NAME = \"online_recommendations_pr_final\"\n",
    "RUN_NAME = \"range_model_8\"\n",
    "\n",
    "\n",
    "if client.get_experiment_by_name(EXPERIMENT_NAME) is None:\n",
    "    experiment_id = client.create_experiment(EXPERIMENT_NAME)\n",
    "else:\n",
    "    experiment_id = client.get_experiment_by_name(EXPERIMENT_NAME).experiment_id\n",
    "\n",
    "\n",
    "mlflow.set_tracking_uri(client.tracking_uri)\n",
    "mlflow.set_registry_uri(client.tracking_uri)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6cd3e1e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/09/29 08:05:08 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n",
      "\u001b[31m2025/09/29 08:05:13 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001b[0m\n",
      "Registered model 'catboost_ranker_ratio5' already exists. Creating a new version of this model...\n",
      "2025/09/29 08:05:19 INFO mlflow.store.model_registry.abstract_store: Waiting up to 300 seconds for model version to finish creation. Model name: catboost_ranker_ratio5, version 3\n",
      "Created version '3' of model 'catboost_ranker_ratio5'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🏃 View run range_model_8 at: http://127.0.0.1:5000/#/experiments/17/runs/ae9b5c42705744bb9e20b541379157e2\n",
      "🧪 View experiment at: http://127.0.0.1:5000/#/experiments/17\n"
     ]
    }
   ],
   "source": [
    "# Начинаем MLflow run\n",
    "with mlflow.start_run(run_name=RUN_NAME, experiment_id=experiment_id):\n",
    "    # Логируем параметры\n",
    "    params = {\n",
    "        \"iterations\": 1500,\n",
    "        \"learning_rate\": 0.05,\n",
    "        \"depth\": 8,\n",
    "        \"l2_leaf_reg\": 3.0,\n",
    "        \"loss_function\": \"YetiRank\",\n",
    "        \"eval_metric\": \"NDCG:top=10\",\n",
    "        \"random_seed\": 42,\n",
    "        \"od_type\": \"Iter\",\n",
    "        \"od_wait\": 50,\n",
    "        \"pos_neg_ratio\": \"1:5\",\n",
    "        \"n_features\": len(features),\n",
    "        \"n_cat_features\": len(cat_features),\n",
    "        \"train_size\": len(train_part),\n",
    "        \"valid_size\": len(valid_part),\n",
    "        \"test_size\": len(test),\n",
    "    }\n",
    "\n",
    "    mlflow.log_params(params)\n",
    "\n",
    "    # Логируем списки фичей\n",
    "    mlflow.log_text(\"\\n\".join(features), \"features.txt\")\n",
    "    mlflow.log_text(\"\\n\".join(cat_features), \"categorical_features.txt\")\n",
    "\n",
    "    for metric_name, metric_value in valid_metrics.items():\n",
    "        mlflow.log_metric(f\"valid_{metric_name}\", metric_value)\n",
    "\n",
    "    for metric_name, metric_value in test_metrics.items():\n",
    "        mlflow.log_metric(f\"test_{metric_name}\", metric_value)\n",
    "\n",
    "    mlflow.catboost.log_model(\n",
    "        model, \"model\", registered_model_name=\"catboost_ranker_ratio5\"\n",
    "    )\n",
    "\n",
    "    mlflow.log_artifacts(str(MODEL_DIR), \"model_files\")\n",
    "    try:\n",
    "        feature_importance = model.get_feature_importance(test_pool)\n",
    "        importance_df = pd.DataFrame(\n",
    "            {\"feature\": features, \"importance\": feature_importance}\n",
    "        ).sort_values(\"importance\", ascending=False)\n",
    "\n",
    "        importance_path = MODEL_DIR / \"feature_importance.csv\"\n",
    "        importance_df.to_csv(importance_path, index=False)\n",
    "        mlflow.log_artifact(str(importance_path), \"feature_importance\")\n",
    "\n",
    "        # Логируем топ-10 важных фичей как параметры\n",
    "        for i, (feat, imp) in enumerate(importance_df.head(10).values):\n",
    "            mlflow.log_param(f\"top_feature_{i + 1}\", f\"{feat}:{imp:.4f}\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Не удалось получить feature importance: {e}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mle-pr-final",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
